Apache Kafka – это распределённая и легко масштабируемая система обмена сообщениями с высокой пропускной способностью, которая может в реальном времени обрабатывать любые объемы данных.
На горячую количество партиций можно только увеличить, для уменьшения необходимо пересоздать топик.

Для увеличения количества партиций, переходим в директорию где у нас установлена Kafka

./bin/kafka-topics.sh --alter --zookeeper <zookeeper_ip>:2181 --partitions <count> --topic <topic_name>
zookeeper_ip - IP адрес сервера zookeeper, для лкоальной установки localhost
count - количество партиций
topic_name - имя топика

Метод 1: Round Robin или Spraying (по умолчанию)
В этом методе разделитель будет посылать сообщения всем партициям по кругу, обеспечивая сбалансированную нагрузку на сервер.

Для примера создадим топик (с тремя репликами и тремя партициями) с именем топика "test2":

./kafka-topics.sh --create --zookeeper localhost:2181 --topic test --replication-factor 3 --partitions 3
Опубликуем тот же набор данных в новой топике test2:

/.kafka-console-producer.sh --topic test2 --bootstrap-server localhost:9092
&gt;0001,Test1,credit,10000
&gt;0002,Test2,debit,20000
&gt;0003,Test3,credit,30000
&gt;0004,Test4,debit,40000
&gt;0005,Test5,debit,50000
Давайте создадим потребителя, который будет получать сообщения из Kafka:

./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test2 --from-beginning
&gt;0004,Test4,debit,40000
&gt;0001,Test1,credit,10000
&gt;0003,Test3,credit,30000
&gt;0002,Test2,debit,20000
&gt;0005,Test5,debit,50000
Давайте разберемся, что происходит под капотом. Есть три раздела (A, B и C). Раздел B работает быстро благодаря низкой сетевой и системной задержке, и сообщения, отправленные на него, были получены первыми. Затем идет раздел C, за которым следует A.

Этим методом достигается параллелизм и балансировка нагрузки, но не удается сохранить общий порядок, однако порядок внутри раздела сохраняется. Это метод по умолчанию, и он не подходит для некоторых бизнес-сценариев. Если дебетовая транзакция произойдет раньше кредитной, то это будет неясно для бизнес-пользователей, которые потребляют сообщения.

Для того чтобы преодолеть описанные выше сценарии и сохранить порядок сообщений, давайте попробуем другой подход.



Метод 2: Хеширование ключевых разделов
В этом методе мы можем создать ProducerRecord, указать ключ сообщения, вызвав new ProducerRecord (имя топика, ключ сообщения, сообщение).

Разделитель по умолчанию будет использовать хэш ключа, чтобы гарантировать, что все сообщения для одного и того же ключа попадут к одному и тому же производителю. Это самый простой и наиболее распространенный подход. Это тот же метод, который использовался. Для хеширования используется операция модуляции.

Hash(Key) % Количество партиций -> Номер партиции

Однако простая отправка строк текста приведет к сообщениям с нулевыми ключами. Чтобы отправлять сообщения с ключами и значениями, мы должны установить свойства parse.key и key.separator в командной строке при запуске производителя.

Ниже приведен фрагмент кода для метода хэширования, который устанавливает свойство parse.key в true, а для key.separator задает ":".

В приведенном ниже примере сообщений ключами являются key1, key2, а значениями - value1, value2.

-- broker-list localhost:9092 \
-- topic topic-name \
-- property "parse.key=true" \
-- property "key.separator=:"
key1:value1
key2:value2
Давайте создадим топик (с тремя репликами и тремя партициями) с именем темы test1:

./kafka-topics.sh --create --zookeeper localhost:2181 --topic test1 --replication-factor 3 --partitions 3
И опубликуем несколько сообщений в топике test1 с ключевым значением для всех записей:

./kafka-console-producer.sh --topic test1 --bootstrap-server localhost:9092 --property "parse.key=true" --property "key.separator=:"
&gt;0001:0001,Test1,credit,10000
&gt;0002:0002,Test2,debit,20000
&gt;0001:0001,Test3,credit,30000
&gt;0002:0002,Test4,debit,40000
&gt;0001:0001,Test5,debit,50000
Как видно ниже, порядок сообщений внутри ключей сохраняется.

./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test1 --from-beginning

./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test1 --from-beginning
&gt;0002:0002,Test2,debit,20000
&gt;0002:0002,Test4,debit,40000
&gt;0001:0001,Test1,credit,10000
&gt;0001:0001,Test3,credit,30000
&gt;0001:0001,Test5,debit,50000
Брокер назначает ключ 0001 для раздела A (раздел с высокой задержкой) и ключ 0002 для раздела B (раздел с низкой задержкой), используя метод хэширования ключей. Потребитель потребляет сообщение, основываясь на значении ключа в заказе.

С помощью этого метода мы можем поддерживать порядок сообщений в пределах ключа.

Но недостатком этого метода является то, что он использует случайное значение хэширования для передачи данных в назначенный раздел, и это приводит к перегрузке данных в один раздел.



Метод 3: Пользовательский разделитель
Мы можем написать собственную бизнес-логику, чтобы решить, какое сообщение должно быть отправлено в тот или иной раздел. При таком подходе мы можем упорядочить сообщения в соответствии с нашей бизнес-логикой и одновременно добиться параллелизма.
